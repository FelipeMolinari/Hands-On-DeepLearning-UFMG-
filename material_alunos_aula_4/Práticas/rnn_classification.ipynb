{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rnn_classification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"xWbKs2L2VLAN","colab_type":"text"},"source":["# Classificando nomes com uma *Character-Level RNN*"]},{"cell_type":"markdown","metadata":{"id":"JzlUoQmIVPod","colab_type":"text"},"source":["https://github.com/spro/practical-pytorch/blob/master/char-rnn-classification/char-rnn-classification.ipynb\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"u3yTcZViBgS8","colab_type":"text"},"source":["### Problema: Dado um nome próprio de entrada, classificar esse nome de acordo com a nacionalidade a que ele pertence."]},{"cell_type":"markdown","metadata":{"id":"ehwomfzYVZNe","colab_type":"text"},"source":["python predict.py **Hinton**\n","\n","(-0.47) Scottish\n","\n","(-1.52) English\n","\n","(-3.57) Irish\n","\n","\n","-\n","\n","python predict.py **Schmidhuber**\n","\n","(-0.19) German\n","\n","(-2.48) Czech\n","\n","(-2.68) Dutch"]},{"cell_type":"markdown","metadata":{"id":"-r2eSYyYB78h","colab_type":"text"},"source":["\n","---\n","### Import de bibliotecas"]},{"cell_type":"code","metadata":{"id":"PIPESSWBeXKC","colab_type":"code","colab":{}},"source":["import unicodedata\n","import torch\n","import string\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import sys, random, os\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","from sklearn.model_selection import train_test_split as split\n","\n","args = {\n","    'lr': 1e-4,\n","    'weight_decay': 5e-6 \n","}\n","\n","if torch.cuda.is_available():\n","  args['device'] = torch.device('cuda')\n","else:\n","  args['device'] = torch.device('cpu')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"skDOjmZZCCzc","colab_type":"text"},"source":["\n","---\n","\n","### Importando dataset"]},{"cell_type":"code","metadata":{"id":"T09ezsbbVETm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":651},"outputId":"93a00764-3eda-4a23-91aa-f5b01cc15563","executionInfo":{"status":"ok","timestamp":1582981690817,"user_tz":180,"elapsed":5274,"user":{"displayName":"Camila Laranjeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz7WDIBQ3wOEmidIKdRUS7fGKCuZVQijzJHWlRLjg=s64","userId":"03895474106233302954"}}},"source":["# comente as duas linhas seguintes caso rode mais de uma vez\n","!wget https://download.pytorch.org/tutorial/data.zip #\n","!unzip data.zip #\n","############################################################\n","\n","root_path = 'data/names/'\n","all_filenames = []\n","for file_name in os.listdir(root_path):\n","  all_filenames.append(os.path.join(root_path,file_name))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-02-29 13:08:04--  https://download.pytorch.org/tutorial/data.zip\n","Resolving download.pytorch.org (download.pytorch.org)... 99.84.251.95, 99.84.251.22, 99.84.251.61, ...\n","Connecting to download.pytorch.org (download.pytorch.org)|99.84.251.95|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2882130 (2.7M) [application/zip]\n","Saving to: ‘data.zip’\n","\n","\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip            100%[===================>]   2.75M  17.0MB/s    in 0.2s    \n","\n","2020-02-29 13:08:05 (17.0 MB/s) - ‘data.zip’ saved [2882130/2882130]\n","\n","Archive:  data.zip\n","   creating: data/\n","  inflating: data/eng-fra.txt        \n","   creating: data/names/\n","  inflating: data/names/Arabic.txt   \n","  inflating: data/names/Chinese.txt  \n","  inflating: data/names/Czech.txt    \n","  inflating: data/names/Dutch.txt    \n","  inflating: data/names/English.txt  \n","  inflating: data/names/French.txt   \n","  inflating: data/names/German.txt   \n","  inflating: data/names/Greek.txt    \n","  inflating: data/names/Irish.txt    \n","  inflating: data/names/Italian.txt  \n","  inflating: data/names/Japanese.txt  \n","  inflating: data/names/Korean.txt   \n","  inflating: data/names/Polish.txt   \n","  inflating: data/names/Portuguese.txt  \n","  inflating: data/names/Russian.txt  \n","  inflating: data/names/Scottish.txt  \n","  inflating: data/names/Spanish.txt  \n","  inflating: data/names/Vietnamese.txt  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ltk3-NJabrHz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"9ca6d9cb-81d7-4492-da5d-8bd3eada6a05","executionInfo":{"status":"ok","timestamp":1582981702056,"user_tz":180,"elapsed":1448,"user":{"displayName":"Camila Laranjeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz7WDIBQ3wOEmidIKdRUS7fGKCuZVQijzJHWlRLjg=s64","userId":"03895474106233302954"}}},"source":["category_lines = {}\n","all_categories = []\n","\n","# Read a file and split into lines\n","def readLines(filename):\n","    lines = open(filename).read().strip().split('\\n')\n","    #return lines\n","    return [unicodedata.normalize('NFKD', line).encode('ascii', 'ignore') for line in lines]\n","\n","for filename in all_filenames:\n","    category = filename.split('/')[-1].split('.')[0]\n","    all_categories.append(category)\n","    lines = readLines(filename)\n","    category_lines[category] = lines\n","\n","n_categories = len(all_categories)\n","print('n_categories =', n_categories)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["n_categories = 18\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mi6dNGFLdNU6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"56d87131-7b3e-45c0-f9fa-f95d724aed81","executionInfo":{"status":"ok","timestamp":1582981707696,"user_tz":180,"elapsed":719,"user":{"displayName":"Camila Laranjeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz7WDIBQ3wOEmidIKdRUS7fGKCuZVQijzJHWlRLjg=s64","userId":"03895474106233302954"}}},"source":["category_lines['Portuguese'][:5]"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[b'Abreu', b'Albuquerque', b'Almeida', b'Alves', b'Araujo']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"BN_P5qE9DD7f","colab_type":"text"},"source":["\n","---\n","### Convertendo caracteres para tensores\n","Nesse caso, cada caracter será convertido para uma representação *one-hot*\n"]},{"cell_type":"code","metadata":{"id":"AxEA1ClZds4c","colab_type":"code","colab":{}},"source":["all_letters = string.ascii_letters + \" .,;'\"\n","n_letters = len(all_letters)\n","\n","# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n","def letter_to_tensor(letter):\n","    tensor = torch.zeros(1, n_letters)\n","    letter_index = all_letters.find(letter)\n","    tensor[0][letter_index] = 1\n","    return tensor\n","\n","# Turn a line into a <line_length x 1 x n_letters>,\n","# or an array of one-hot letter vectors\n","def line_to_tensor(line):\n","    tensor = torch.zeros(len(line), 1, n_letters)\n","    for li, letter in enumerate(line.decode('utf-8')):\n","        letter_index = all_letters.find(letter)\n","        tensor[li][0][letter_index] = 1\n","    return tensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Sv4Giioe8RS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":110},"outputId":"eba58765-8906-4ab5-b910-f7de047921bb","executionInfo":{"status":"ok","timestamp":1582981749157,"user_tz":180,"elapsed":783,"user":{"displayName":"Camila Laranjeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giz7WDIBQ3wOEmidIKdRUS7fGKCuZVQijzJHWlRLjg=s64","userId":"03895474106233302954"}}},"source":["tns = letter_to_tensor('A')\n","print(tns)\n","print(tns.size())"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0.]])\n","torch.Size([1, 57])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T58yGDm8FlSd","colab_type":"text"},"source":["\n","\n","---\n","\n","\n","### Funções auxiliares para estruturar as amostras de treino e teste"]},{"cell_type":"code","metadata":{"id":"Od2ko1iD6krC","colab_type":"code","colab":{}},"source":["def category_from_output(output):\n","    top_n, top_i = output.data.topk(1) # Tensor out of Variable with .data\n","    category_i = top_i[0][0]\n","    return all_categories[category_i]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x3B_1fpTF9P-","colab_type":"code","colab":{}},"source":["X_train, X_test = {}, {}\n","for category in all_categories:\n","  train, test = split(category_lines[category], test_size=0.1)\n","  \n","  X_train[category] = train\n","  X_test[category] = test"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4k4IaUFvDt0v","colab_type":"text"},"source":["\n","\n","---\n","\n","### Construindo modelo RNN\n","\n","* Implemente um modelo para classificação de nomes próprios (série de caracteres) usando apenas camadas *RNNCell*, *Linear* e ativação *LogSoftmax*\n","* Cada entrada (caracter) possui dimensão (57): alfabeto maiúsculo e minúsculo\n","* *Hidden size* possui dimensão (256): hiperparâmetro \n","* Saída possui dimensão (18): vetor de probabilidade de classes\n","* Batch size = 1 de acordo com a implementação do loop de treinamento\n","\n","**Links úteis**\n","\n","RNNCell: https://pytorch.org/docs/stable/nn.html#torch.nn.RNNCell\n","\n","Linear: https://pytorch.org/docs/stable/nn.html#torch.nn.Linear\n","\n","Non-linear activations: https://pytorch.org/docs/stable/nn.html#non-linear-activations-other\n","\n"]},{"cell_type":"code","metadata":{"id":"BtIFLlfKfIBH","colab_type":"code","colab":{}},"source":["# Implemente a classe da sua rede\n","\n","\n","# Defina aqui a sua rede\n","model = ..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jgppRhH7ZRIY","colab_type":"text"},"source":["\n","\n","---\n","\n","### Instanciando *Loss* e Otimizador\n","\n","Utilize a ```NLLLoss``` (Negative Log-Likelihood Loss) já que utilizamos o LogSoftmax como ativação da saída da nossa rede. <br>\n","https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss \n","\n","Utilize o otimizador ```Adam``` com os hiperparâmetros definidos no dicionário ```args``` previamente definido.<br>\n","https://pytorch.org/docs/stable/optim.html#torch.optim.Adam"]},{"cell_type":"code","metadata":{"id":"4HGEyjwRZXjV","colab_type":"code","colab":{}},"source":["criterion = ...\n","optimizer = ..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hpRfr8HrFtF4","colab_type":"text"},"source":["\n","\n","---\n","\n","### Treinando / Testando modelo"]},{"cell_type":"code","metadata":{"id":"vzY7EaLWQpe3","colab_type":"code","colab":{}},"source":["num_epochs = 20\n","num_steps  = 2000\n","print_every = 2000\n","\n","current_loss = 0\n","current_acc = 0\n","all_losses, all_val_losses, all_acc, all_val_acc = [], [], [], []\n","for epoch in range(num_epochs):  \n","\n","  for step in range(num_steps):\n","    \n","    # Set to Train Mode\n","    model.train()\n","    \n","    category = random.choice(all_categories)\n","    line = random.choice(X_train[category])\n","  \n","    category_tensor = Variable(torch.LongTensor([all_categories.index(category)])).to(args['device']) \n","    line_tensor     = Variable(line_to_tensor(line)).double().to(args['device'])\n","\n","    # Forward pass\n","    output = model(line_tensor)\n","    loss = criterion(output, category_tensor)\n","    current_loss += loss\n","    current_acc  += 1 if category_from_output(output) == category else 0\n","    \n","    # Backward and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if (step+1) % print_every == 0:\n","      \n","      #Set to evaluation mode\n","      model.eval()\n","      n_test_steps = 100\n","      \n","      test_loss, acc = 0, 0\n","      for tstep in range(n_test_steps):\n","      \n","        category = random.choice(all_categories)\n","        line = random.choice(X_test[category])\n","\n","        category_tensor = Variable(torch.LongTensor([all_categories.index(category)])).to(args['device'])\n","        line_tensor     = Variable(line_to_tensor(line)).double().to(args['device'])\n","\n","        output = model(line_tensor)\n","        loss = criterion(output, category_tensor)\n","        test_loss += loss\n","        acc += 1 if category_from_output(output) == category else 0\n","      \n","      \n","      current_loss = current_loss.item()/float(print_every)\n","      current_acc  = current_acc/float(print_every)\n","      test_loss    = test_loss.item()/float(n_test_steps)\n","      acc          = acc/float(n_test_steps)\n","      \n","      print('\\rEpoch: {:2} Train Loss: {:.3f} Train Acc: {:.2f}% Val Loss: {:.3f}  Val Acc: {:.2f}%'.format(epoch+1, current_loss, current_acc*100, test_loss, acc*100))\n","\n","      all_losses.append(current_loss)\n","      all_acc.append(current_acc)\n","      all_val_losses.append(test_loss)\n","      all_val_acc.append(acc)\n","\n","      current_loss = 0\n","      current_acc  = 0\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AMJDZoNrW1wN","colab_type":"text"},"source":["\n","\n","---\n","\n","\n","### Análise e plots"]},{"cell_type":"code","metadata":{"id":"V75MN9lf9KRK","colab_type":"code","colab":{}},"source":["fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,3))\n","\n","\n","ax1.plot(all_losses[1:], label='Train')\n","ax1.plot(all_val_losses[1:], label='Test')\n","ax1.set_title('Model Convergence - Loss')\n","ax1.set_xlabel('epochs')\n","ax1.set_ylabel('Loss')\n","ax1.legend()\n","\n","ax2.plot(all_acc, label='Train')\n","ax2.plot(all_val_acc, label='Test')\n","ax2.set_title('Model Convergence - Accuracy')\n","ax2.set_xlabel('epochs')\n","ax2.set_ylabel('Accuracy')\n","ax2.legend()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j5Pr5dvWh_Jb","colab_type":"text"},"source":["\n","\n","---\n","\n","### Fazendo predições com entradas de usuário"]},{"cell_type":"code","metadata":{"id":"_MolDbbq9L8p","colab_type":"code","colab":{}},"source":["def predict_input(input_line, n_predictions=3):\n","    print('\\n> %s' % input_line)\n","    \n","    tensor = torch.zeros(len(input_line),1, n_letters)\n","    for li, letter in enumerate(input_line):\n","        letter_index = all_letters.find(letter)\n","        tensor[li][0][letter_index] = 1\n","        \n","    output = model(Variable(tensor).double().cuda())\n","\n","    # Get top N categories\n","    topv, topi = output.data.topk(n_predictions, 1, True)\n","    predictions = []\n","\n","    for i in range(n_predictions):\n","        value = topv[0][i]\n","        category_index = topi[0][i]\n","        print('(%.2f) %s' % (value, all_categories[category_index]))\n","        predictions.append([value, all_categories[category_index]])\n","\n","predict_input('Mbape')\n","predict_input('Guillermo')\n","predict_input('Kyle')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKdXTtU5QUG7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}