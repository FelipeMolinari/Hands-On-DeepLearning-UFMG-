{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PixelGRU",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT2KT5vRIKmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic imports.\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "from torch.backends import cudnn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from skimage import io\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoQdWCc-ITgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting predefined arguments.\n",
        "args = {\n",
        "    'epoch_num': 50,      # Number of epochs.\n",
        "    'n_classes': 10,      # Number of classes.\n",
        "    'lr': 1e-3,           # Learning rate.\n",
        "    'weight_decay': 5e-4, # L2 penalty.\n",
        "    'momentum': 0.9,      # Momentum.\n",
        "    'num_workers': 3,     # Number of workers on data loader.\n",
        "    'batch_size': 30,     # Mini-batch size.\n",
        "    'visibility': 0.65\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNejlgPiIFqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = './'\n",
        "\n",
        "# Setting dataloader.\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_set = datasets.MNIST(root,\n",
        "                             train=True,\n",
        "                             download=True,\n",
        "                             transform=data_transform)\n",
        "test_set = datasets.MNIST(root,\n",
        "                            train=False,\n",
        "                            download=False,\n",
        "                            transform=data_transform)\n",
        "\n",
        "train_loader = DataLoader(train_set,\n",
        "                          args['batch_size'],\n",
        "                          num_workers=args['num_workers'],\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(test_set,\n",
        "                         args['batch_size'],\n",
        "                         num_workers=args['num_workers'],\n",
        "                         shuffle=True)\n",
        "\n",
        "print('Size of training set: ' + str(len(train_set)) + ' samples')\n",
        "print('Size of test set: ' + str(len(test_set)) + ' samples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkkCWk5LEYuM",
        "colab_type": "text"
      },
      "source": [
        "# Atividade Prática\n",
        "\n",
        "## Pixel RNN\n",
        "\n",
        "Também é possível trabalhar de forma auto-supervisionada usando modelos recorrentes. Um exemplo de destaque é a PixelRNN, que considera cada pixel da imagem como uma unidade de sequência, e propõe um modelo probabilístico para prever o próximo pixel, dada uma sequência de pixels antecessores. A imagem a seguir ilustra essa proposta.\n",
        "* Paper: https://arxiv.org/abs/1601.06759\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=198yw7kilta27G_bx3Ldcjguor_-qkk97\" width=\"250\"><br><br>\n",
        "\n",
        "A melhor configuração dentre as propostas no artigo foi capaz de preencher lacunas em imagens com oclusões artificiais. Note que é preciso alimentar o modelo com uma porção significativa da imagem para que ele seja capaz de prever o restante.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/700/0*o7PUa9K5rPGeFIcx.\" width=\"600\"><br><br>\n",
        "\n",
        "\n",
        "Uma modelagem simples para esse problema é considerar que os pixels da imagem são os elementos da sequência. Sendo a imagem $28 \\times 28$, as seqências terão tamanho fixo de $784$.\n",
        "\n",
        "De acordo com o que foi definido no fluxo de treinamento e teste, temos que:\n",
        "\n",
        "* Entrada: vetor linearizado e com a oclusão artificial ```(batch_size, 784, 1)```. A oclusão ocorre através do preenchimento com zeros em uma região fixa da imagem. O parâmetro ```args['visibility']``` determina o percentual da imagem visível para a rede.\n",
        "* Saída esperada: dígito reconstruído extrapolando a oclusão. Para isso, o cálculo da loss é realizado comparando a reconstrução com o dado **original**. ```(batch_size, 784, 1)```\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1DzHtZXT1dsWm4s7xbZfmu0NiLmKw7jpL)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Defina a sua rede com:\n",
        "* Duas camadas de GRU. Lembre-se que é possível definir múltiplas camadas com a  ```nn.GRU```. Sugestão\n",
        "  * ```hidden_size = 128```\n",
        "  * ```num_layers = 2```\n",
        "  * É preciso definir ```batch_first = True```, pois os dados estão sendo carregados na forma ```(batch_size, seq_len, 1)```\n",
        "  \n",
        "* Uma camada Linear\n",
        "\n",
        "> Atenção: Este é um problema Many-to-Many, ou seja, para cada pixel de entrada sua rede deve inferir qual será o próximo pixel da sequência. Para passar toda a sequência de uma vez na camada Linear, redimensione a saída da GRU para ```(batch_size x seq_len, hidden_size)```.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2i0JrYNfpFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        \n",
        "        \n",
        "\n",
        "    def forward(self, ):\n",
        "\n",
        "        # Inicialize o hidden state\n",
        "              \n",
        "        # Forward na GRU\n",
        "        \n",
        "        # Redimensione a saída da GRU para que ela fique na forma \n",
        "        # (batch_size x seq_len, 1)\n",
        "        # output_rnn.contiguous().view( ... ) \n",
        "\n",
        "        # Forward na camada Linear\n",
        "        \n",
        "        # Redimensione a saída da camada Linear de volta ao formato\n",
        "        # (batch_size, seq_len, 1)\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "# Defina aqui a sua rede\n",
        "pixelrnn = ...\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbfeDoiI_6dl",
        "colab_type": "text"
      },
      "source": [
        "### Loss e Otimizador\n",
        "\n",
        "Defina aqui uma loss de regressão (MSE, L1, etc.) e um otimizador (pode contar com o ADAM sempre!)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZG69bouPpt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = ...\n",
        "\n",
        "optimizer = ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWEsHueEiO_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, net, criterion, optimizer, epoch):\n",
        "\n",
        "    # Setting network for training mode.\n",
        "    net.train()\n",
        "\n",
        "    # Lists for losses and metrics.\n",
        "    train_loss = []\n",
        "    \n",
        "    begin = time.time()\n",
        "    \n",
        "    # Iterating over batches.\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "        if i > 501: break  \n",
        "\n",
        "        # Obtaining images, labels and paths for batch.\n",
        "        inps, _ = batch_data\n",
        "        labs = inps.view(inps.size(0),-1).unsqueeze(-1)\n",
        "        \n",
        "        \n",
        "        # Casting to cuda variables.\n",
        "        inps = inps.to(args['device'])\n",
        "        labs = labs.to(args['device'])\n",
        "        \n",
        "        patch_occ = int(args['visibility'] * 784) \n",
        "        input_occ = torch.zeros(labs.size()).to(args['device'])\n",
        "        input_occ[:,:patch_occ] = labs[:, :patch_occ]\n",
        "        \n",
        "        # Clears the gradients of optimizer.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forwarding.\n",
        "        outs = net(input_occ[:,:-1])\n",
        "\n",
        "        # Computing loss.\n",
        "        loss = 0.\n",
        "        for k, out in enumerate(outs):\n",
        "          loss += criterion(out, labs[k, 1:])\n",
        "        \n",
        "        # Computing backpropagation.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Plot prediction\n",
        "        prds = np.append(np.zeros( (len(outs),1,1) ), outs.detach().data.cpu().numpy(), axis=1)\n",
        "        if i % 250 == 1:\n",
        "          print(loss)\n",
        "          fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(10,5))\n",
        "          \n",
        "          img_label = labs[0].detach().data.cpu().numpy().reshape(inps.size(2), inps.size(3))\n",
        "          axs[0].imshow(img_label, cmap='Greys')\n",
        "          axs[0].set_title('Train - Ground Truth')\n",
        "          \n",
        "          img_label = input_occ[0].detach().data.cpu().numpy().reshape(inps.size(2), inps.size(3))\n",
        "          axs[1].imshow(img_label, cmap='Greys')\n",
        "          axs[1].set_title('Train - Input (Occlusion)')\n",
        "          \n",
        "          img = prds.reshape(inps.size(0), inps.size(2), inps.size(3))[0]\n",
        "          axs[2].imshow(img, cmap='Greys')\n",
        "          axs[2].set_title('Train - Prediction')\n",
        "          \n",
        "          plt.show()\n",
        "          plt.close(fig)\n",
        "          \n",
        "        \n",
        "        # Updating lists.\n",
        "        train_loss.append(loss.data.item())\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    train_loss = np.asarray(train_loss)\n",
        "    \n",
        "    # Printing training epoch loss and metrics.\n",
        "    print('--------------------------------------------------------------------')\n",
        "    print('[epoch %d], [train loss %.4f +/- %.4f | Time: %.2f ]' % (\n",
        "        epoch, train_loss.mean(), train_loss.std(), end-begin))\n",
        "    print('--------------------------------------------------------------------')\n",
        "        \n",
        "    return train_loss.mean(), end-begin\n",
        "    \n",
        "    \n",
        "def test(test_loader, net, criterion, epoch):\n",
        "\n",
        "    # Setting network for evaluation mode.\n",
        "    net.eval()\n",
        "\n",
        "    # Lists for losses and metrics.\n",
        "    test_loss = []\n",
        "    prd_list = []\n",
        "    lab_list = []\n",
        "    \n",
        "    begin = time.time()\n",
        "    \n",
        "    # Iterating over batches.\n",
        "    for i, batch_data in enumerate(test_loader):\n",
        "        if i > 401: break\n",
        "\n",
        "        # Obtaining images, labels and paths for batch.\n",
        "        inps, _ = batch_data\n",
        "        labs = inps.view(inps.size(0),-1).unsqueeze(-1)\n",
        "\n",
        "        # Casting to cuda variables.\n",
        "        inps = inps.to(args['device'])\n",
        "        labs = labs.to(args['device'])\n",
        "        \n",
        "        patch_occ = int(args['visibility'] * 784) \n",
        "        input_occ = torch.zeros(labs.size()).to(args['device'])\n",
        "        input_occ[:,:patch_occ] = labs[:, :patch_occ]\n",
        "\n",
        "        # Forwarding.\n",
        "        outs = net(input_occ[:, :-1])\n",
        "\n",
        "        # Plot prediction\n",
        "        prds = np.append(np.zeros( (len(outs),1,1) ), outs.detach().data.cpu().numpy(), axis=1)\n",
        "        if i % 250 == 1:\n",
        "          print(loss)\n",
        "          fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(10,5))\n",
        "          \n",
        "          img_label = labs[0].detach().data.cpu().numpy().reshape(inps.size(2), inps.size(3))\n",
        "          axs[0].imshow(img_label, cmap='Greys')\n",
        "          axs[0].set_title('Test - Ground Truth')\n",
        "          \n",
        "          img_label = input_occ[0].detach().data.cpu().numpy().reshape(inps.size(2), inps.size(3))\n",
        "          axs[1].imshow(img_label, cmap='Greys')\n",
        "          axs[1].set_title('Test - Input (Occlusion)')\n",
        "          \n",
        "          img = prds.reshape(inps.size(0), inps.size(2), inps.size(3))[0]\n",
        "          axs[2].imshow(img, cmap='Greys')\n",
        "          axs[2].set_title('Test - Prediction')\n",
        "          \n",
        "          plt.show()\n",
        "          plt.close(fig)\n",
        "        \n",
        "        # Computing loss.\n",
        "        loss = 0.\n",
        "        for k, out in enumerate(outs):\n",
        "          loss += criterion(out, labs[k, 1:])\n",
        "        \n",
        "        # Obtaining predictions.\n",
        "        prds = outs.data.max(dim=1)[1].cpu().numpy()\n",
        "        \n",
        "        # Updating lists.\n",
        "        test_loss.append(loss.data.item())\n",
        "        prd_list.append(prds)\n",
        "        lab_list.append(labs.detach().cpu().numpy())\n",
        "        \n",
        "    end = time.time()\n",
        "    \n",
        "    # Computing accuracy.\n",
        "    \n",
        "    test_loss = np.asarray(test_loss)\n",
        "    \n",
        "    # Printing training epoch loss and metrics.\n",
        "    print('--------------------------------------------------------------------')\n",
        "    print('[epoch %d], [test loss %.4f +/- %.4f | Time: %.2f]' % (\n",
        "        epoch, test_loss.mean(), test_loss.std(), end-begin))\n",
        "    print('--------------------------------------------------------------------')\n",
        "    \n",
        "    return test_loss.mean(), end-begin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlbssN1AiuOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iterating over epochs.\n",
        "for epoch in range(1, args['epoch_num'] + 1):\n",
        "\n",
        "#     Training function.\n",
        "    train(train_loader, pixelrnn, criterion, optimizer, epoch)\n",
        "\n",
        "    # Computing test loss and metrics.\n",
        "    test(test_loader, pixelrnn, criterion, epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZdrexdqjWn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}