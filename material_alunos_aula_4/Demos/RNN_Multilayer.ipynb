{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN Multilayer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl1SAtKUo5S1",
        "colab_type": "text"
      },
      "source": [
        "## Pytorch RNN \n",
        "\n",
        "Documentação: https://pytorch.org/docs/stable/nn.html#torch.nn.RNN\n",
        "\n",
        "A camada RNN encapsula todo o processamento na dimensão do tempo, **eliminando a necessidade de realizar um loop explícito na implementação do forward**. A implementação dessa camada no pytorch espera uma entrada na forma ```(seq_len, batch_size, input_size)```, apresentando uma saída na forma  ```(seq_len, batch_size, hidden_size)```. Isso pode ser alterado definindo o parâmetro ```batch_first = True``` ao instanciar a camada, artifício útil quando se utiliza o DataLoader para carregamento dos dados.\n",
        "\n",
        "Outra vantagem é a possibilidade de implementar **múltiplas camadas ao mesmo tempo** com a simples definição de um parâmetro inteiro ```num_layers``` ao instanciar a RNN.\n",
        "\n",
        "### Multilayer RNN\n",
        "\n",
        "#### Com a camada RNNCell\n",
        "``` python\n",
        "# Definição de camadas\n",
        "self.rnn1 = nn.RNNCell(input_size, hidden_size)\n",
        "self.rnn2 = nn.RNNCell(hidden_size, hidden_size)\n",
        "\n",
        "# Forward\n",
        "h_layer1 = torch.randn(self.batch_size, self.hidden_size)\n",
        "h_layer2 = torch.randn(self.batch_size, self.hidden_size)\n",
        "\n",
        "for x in X:\n",
        "  h_layer1 = self.rnn1(x, h_layer1)\n",
        "  h_layer2 = self.rnn2(h_layer1, h_layer2)\n",
        "```\n",
        "\n",
        "#### Com a camada RNN\n",
        "\n",
        "``` python\n",
        "# Definição de camadas\n",
        "self.rnn = nn.RNN(input_size, hidden_size, num_layers)\n",
        "\n",
        "# Forward\n",
        "h = torch.randn(self.num_layers, self.batch_size, self.hidden_size)\n",
        "output, h = self.rnn(X, h) \n",
        "# output size = (seq_len, batch_size, hidden_size)\n",
        "# h size = (num_layers, batch_size, hidden_size)\n",
        "```\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=16E2NJxWY14jj3Qq5RaUvodqpd3Sd-ECZ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhWe-vVumw8x",
        "colab_type": "code",
        "outputId": "112d7049-39e5-4eb4-9ca3-870f79860509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_size, hidden_size, batch_size, num_layers):\n",
        "    super(RNN, self).__init__()\n",
        "    \n",
        "    self.hidden_size = hidden_size\n",
        "    self.batch_size  = batch_size\n",
        "    self.num_layers  = num_layers\n",
        "    \n",
        "    self.rnn = nn.RNN(input_size, hidden_size, num_layers)\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "    # Initialize hidden state for first iteration\n",
        "    H = torch.randn(self.num_layers, self.batch_size, self.hidden_size).to(args['device'])\n",
        "\n",
        "    # Iterative forward\n",
        "    outputs, H = self.rnn(X, H)\n",
        "    print('Output size:', outputs.size(), \"\\nHidden Size:\", H.size())\n",
        "    \n",
        "    return outputs\n",
        "\n",
        "seq_len     = 50\n",
        "batch_size  = 10\n",
        "input_size  = 100\n",
        "hidden_size = 512\n",
        "num_layers  = 2\n",
        "\n",
        "net = RNN(input_size, hidden_size, batch_size, num_layers).to(args['device'])\n",
        "\n",
        "## Generate random batch \n",
        "X = torch.randn(seq_len, batch_size, input_size).to(args['device'])\n",
        "\n",
        "## Forward\n",
        "output = net(X)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output size: torch.Size([50, 10, 512]) \n",
            "Hidden Size: torch.Size([2, 10, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}