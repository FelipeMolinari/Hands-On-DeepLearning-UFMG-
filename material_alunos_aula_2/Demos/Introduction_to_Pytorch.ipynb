{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction_to_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG-mVsVuE0if",
        "colab_type": "text"
      },
      "source": [
        "# Preâmbulo\n",
        "\n",
        "Imports básicos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEHmMCjR4PJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic imports.\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from skimage import io\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20kc9tHQ59ba",
        "colab_type": "text"
      },
      "source": [
        "# Sintaxe básica do Pytorch\n",
        "\n",
        "Assim como o NumPy e o MXNet, o Pytorch é uma biblioteca de processamento vetorial/matricial/tensorial. Operações sobre os tensores do Pytorch possuem sintaxe consideravelmente parecida com operações sobre tensores do NumPy e MXNet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQa4-lUw7Rmp",
        "colab_type": "text"
      },
      "source": [
        "## Casting para o dispositivo correto\n",
        "\n",
        "Como usaremos processamento vetorial principalmente em GPUs para aprendizado profundo, primeiramente é possível verificar se há uma GPU disponível com o trecho de código abaixo, armazenando os tensores nos dispositivos apropriados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX0bBEM863sY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking if GPU/CUDA is available.\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd-pMj8dUe_7",
        "colab_type": "text"
      },
      "source": [
        "## Tensores no Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUGDZvJQWrt7",
        "colab_type": "text"
      },
      "source": [
        "Criando tensores novos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsutJ9TGUeaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tns = torch.tensor([1, 2, 3, 4, 5, 6])\n",
        "print(tns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMHSDZ11WuI9",
        "colab_type": "text"
      },
      "source": [
        "Reorganizando tensores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_ZEyjqfUm_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tns.view(2, 3))\n",
        "\n",
        "# Function view() with -1 infers the shape according to the remaining elements.\n",
        "print(tns.view(3, -1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPG9xbsmUtc0",
        "colab_type": "text"
      },
      "source": [
        "Iniciando tensores vazios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4Ho1QAtUwN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tns_0 = torch.zeros(2, 3)\n",
        "tns_1 = torch.ones(2, 3)\n",
        "\n",
        "print(tns_0)\n",
        "print(tns_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laGvfy36U7j5",
        "colab_type": "text"
      },
      "source": [
        "Iniciando tensores com valores aleatórios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9STHuglU-l4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tns_u = torch.rand(2, 3) # Flat distribution.\n",
        "print(tns_u)\n",
        "\n",
        "tns_n = torch.randn(2, 3) # Normal Distribution.\n",
        "print(tns_n)\n",
        "\n",
        "tns_perm = torch.randperm(6) # Random permutation of the interval [0, 5].\n",
        "print(tns_perm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTv86tHOVd7j",
        "colab_type": "text"
      },
      "source": [
        "Operações com tensores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeorfO9mVgHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tns_u)\n",
        "print(tns_n)\n",
        "\n",
        "tns_sum = tns_u + tns_n\n",
        "print(tns_sum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygc7jz5ZV1tc",
        "colab_type": "text"
      },
      "source": [
        "Indexação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7D3DEWHV3sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tns_sum[1, 1]) # Indexing element.\n",
        "print(tns_sum[0, :]) # Indexing line.\n",
        "print(tns_sum[:, 1]) # Indexing column."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcLFvWE5WIES",
        "colab_type": "text"
      },
      "source": [
        "Convertendo de tensores do numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv32OH4IWMI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_arr = np.random.randn(2, 3)\n",
        "print(np_arr, np_arr.dtype)\n",
        "\n",
        "torch_tns = torch.from_numpy(np_arr)\n",
        "print(torch_tns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_Hu59yTXsf2",
        "colab_type": "text"
      },
      "source": [
        "Concatenando tensores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szn-OZAHXuCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tns_u)\n",
        "print(tns_n)\n",
        "\n",
        "tns_cat = torch.cat((tns_u, tns_n), 0)\n",
        "print(tns_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi1pGoSLYMcd",
        "colab_type": "text"
      },
      "source": [
        "Várias outras operações sobre tensores do Pytorch podem ser vistas nos seguintes tutoriais:\n",
        "1.   https://jhui.github.io/2018/02/09/PyTorch-Basic-operations/\n",
        "2.   https://pytorch.org/tutorials/beginner/pytorch_with_examples.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9LoXL0cUYMT",
        "colab_type": "text"
      },
      "source": [
        "## Treinando uma MLP simples em dados aleatórios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi3Zh8fQ4X_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6lK3VO99mSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Casting tensors to the appropriate device.\n",
        "x = x.to(device)\n",
        "y = y.to(device)\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsSQ00w69h6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Printing sizes of tensors.\n",
        "print(x.size())\n",
        "print(y.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMDN1viW-0Eg",
        "colab_type": "text"
      },
      "source": [
        "## Definindo arquitetura, loss e otimizador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYO7HWC29Ahy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the nn package to define our model.\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(D_in, H),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(H, D_out),\n",
        ").to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T83-DZW-Mu_",
        "colab_type": "code",
        "outputId": "59201576-ba24-4695-e161-672939d6597f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=1000, out_features=100, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oQ2T8jm9BE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the nn package to define our loss function.\n",
        "loss_fn = nn.MSELoss(reduction='sum').to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa5DcYBf82iD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the optim package to define an Optimizer that will update the weights of\n",
        "# the model for us. Here we will use Adam; the optim package contains many other\n",
        "# optimization algoriths. The first argument to the Adam constructor tells the\n",
        "# optimizer which Tensors it should update.\n",
        "learning_rate = 1e-4\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPQtOnNr-kAG",
        "colab_type": "text"
      },
      "source": [
        "## Minimizando o erro entre $f(x)$ e $y$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsMFRIDv80I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating list of losses for each epoch.\n",
        "loss_list = []\n",
        "\n",
        "# Iterating over epochs.\n",
        "for epoch in range(500):\n",
        "    \n",
        "    # Forward pass: compute predicted y by passing x to the model.\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    \n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print('Epoch ' + str(epoch + 1) + ': loss = ' + str(loss.item()))\n",
        "    \n",
        "    # Updating list of losses for printing.\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "    # Before the backward pass, use the optimizer object to zero all of the\n",
        "    # gradients for the variables it will update (which are the learnable\n",
        "    # weights of the model). This is because by default, gradients are\n",
        "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
        "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    # parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Calling the step function on an Optimizer makes an update to its\n",
        "    # parameters\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toQyqq98-68X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
        "\n",
        "ax.plot(np.asarray(loss_list))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}