{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"MLP_Classification_MNIST.ipynb","provenance":[{"file_id":"1FoRodH6EcLFxookZdDgcz1MIMJMtko42","timestamp":1581132031693},{"file_id":"1iBi6UeyI2-l9lZBve2SQiv3EIL9Wt-Ai","timestamp":1581130374675},{"file_id":"1Y1skfCJXPaZD7urPYYGOrNMaFSGU6h7v","timestamp":1581113055073},{"file_id":"1xEP0AA_NpC_P-XpdnxL1O7Ny9sHc8uF-","timestamp":1581112306324},{"file_id":"1Ryrv4mhgBXqllQNu5mWHH8En5O-WjCf7","timestamp":1532878867492}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Il7H73VGJ2No"},"source":["# Training Procedure\n","\n","Imports básicos."]},{"cell_type":"code","metadata":{"id":"5LaoPWO9RhEq","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","import torch"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5yNikfN0J2Np"},"source":["## Setting data loader\n","\n","Utilizando o dataset padrão do MNIST disponibilizado pelo pacote torchvision. Para mais informações sobre o dataset, acesse a página: <https://pytorch.org/docs/stable/torchvision/datasets.html#mnist>."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YKPo231vJ2Nq","colab":{}},"source":["from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision import transforms\n","\n","from matplotlib import pyplot as plt\n","\n","%matplotlib inline\n","\n","transf = transforms.Compose([transforms.ToTensor()])\n","\n","train_set = datasets.MNIST('./', transform=transf, train=True, download=True)\n","test_set = datasets.MNIST('./', transform=transf, train=False, download=False)\n","\n","# Plotting samples.\n","fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n","\n","ax[0].imshow(train_set[0][0].numpy().squeeze())\n","ax[0].set_yticks([])\n","ax[0].set_xticks([])\n","\n","ax[1].imshow(test_set[0][0].numpy().squeeze())\n","ax[1].set_yticks([])\n","ax[1].set_xticks([])\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrMULqqYShdC","colab_type":"code","colab":{}},"source":["# Creating data loaders.\n","batch_size = 1000\n","\n","train_loader = DataLoader(train_set, batch_size, shuffle=True)\n","test_loader = DataLoader(test_set, batch_size, shuffle=False)\n","\n","for i, data in enumerate(train_loader):\n","    \n","    inps, labs = data\n","    print(inps.size(), labs.size())\n","    print('')\n","\n","    if i > 5:\n","        break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EGtnadiqJ2Nu"},"source":["## Setting architecture\n","\n","Defina a arquitetura da sua Rede Neural. O pacote torch.nn que contém as implementações de todas as camadas que serão usadas nessa parte (nn.Linear): <https://pytorch.org/docs/stable/nn.html>."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P4oFGFAKJ2Nv","colab":{}},"source":["import torch.nn as nn\n","\n","# Random initialization for weights and biases.\n","def initialize_weights(*models):\n","    for model in models:\n","        for module in model.modules():\n","            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n","                nn.init.kaiming_normal_(module.weight)\n","                if module.bias is not None:\n","                    module.bias.data.zero_()\n","            elif isinstance(module, nn.BatchNorm2d):\n","                module.weight.data.fill_(1)\n","                module.bias.data.zero_()\n","\n","# Customized Network.\n","class CustomNetwork(nn.Module):\n","    \n","    def __init__(self, input_size, n_classes):\n","\n","        super(CustomNetwork, self).__init__()\n","        \n","        # TO DO...\n","\n","    # Forward function.\n","    def forward(self, x):\n","        \n","        # TO DO...\n","        \n","# Instancing Network.\n","input_size = 784 # Input size (28*28).\n","n_classes = 10 # Number of classes on MNIST.\n","\n","# model = CustomNetwork(input_size) # CPU version.\n","model = CustomNetwork(input_size, n_classes).cuda() # GPU casting.\n","\n","initialize_weights(model)\n","\n","# Printing NN.\n","print(model)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VOVXXfCiJ2Ny"},"source":["## Setting optimizer\n","\n","O $Pytorch$ tem várias opções de otimizadores, desde os mais simples como o SGD até adaptadores mais modernos com velocidades de aprendizado adaptáveis para cada parâmetro da rede (i.e. Adam, Adagrad, RSMProp...). Todos os otimizadores estão localizados no pacote torch.optim. Para mais informnações sobre o pacote, visite: <https://pytorch.org/docs/stable/optim.html>."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fhyopppRJ2Nz","colab":{}},"source":["import torch.optim as optim\n","\n","# TO DO..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MlBTGdzPJ2N1"},"source":["## Setting loss criterion\n","\n","Definindo um critério (loss) de classificação para calcular o erro do seu modelo a cada batch de amostras. A $CrossEntropyLoss$ ou a $NLLLoss$ são funções de perda indicadas para esse tipo de tarefa. Informações sobre essas losses podem ser encontradas em: <https://pytorch.org/docs/stable/nn.html#loss-functions>. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H1WirBm_J2N2","colab":{}},"source":["# Setting classification loss.\n","# TO DO..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"d9uC1yHfJ2N4"},"source":["## Training/Testing\n","\n","Iterando sobre batches de treino e teste ao longo de várias epochs."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"04-4qarbJ2N5","colab":{}},"source":["from matplotlib import pyplot as plt\n","from torch.autograd import Variable\n","\n","%matplotlib inline\n","\n","epochs = 10 # Number of training and testing epochs.\n","\n","training_metrics = list() # List for accuracies in training procedure.\n","test_metrics = list() # List for accuracies in test procedure.\n","\n","# Iterating over epochs.\n","for ep in range(epochs):\n","    \n","    print('##############################################')\n","    print('Starting epoch ' + str(ep + 1) + '/' + str(epochs) + '...')\n","    \n","    #####################################################################\n","    # Training Procedure. ###############################################\n","    #####################################################################\n","    \n","    print('    Training...')\n","    \n","    # Setting model to training mode.\n","    model.train()\n","    \n","    # Iterating over training batches.\n","    for it, data in enumerate(train_loader):\n","\n","        # TO DO...\n","\n","    #####################################################################\n","    # Testing Procedure.  ###############################################\n","    #####################################################################\n","    \n","    print('    Testing...')\n","    \n","    # Setting model to evaluation mode.\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        label_list = list()\n","        output_list = list()\n","\n","        # Iterating over test batches.\n","        for it, data in enumerate(test_loader):\n","            \n","            # TO DO...\n","\n","        label_array = np.asarray(label_list, dtype=np.int).ravel()\n","        output_array = np.asarray(output_list, dtype=np.int).ravel()\n","\n","        print('Epoch: %d, Accuracy: %.2f%%' % (ep + 1, 100.0 * np.sum(label_array == output_array) / float(label_array.shape[0])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t8iWQH_grcP-","colab_type":"code","colab":{}},"source":["# Transforming list into ndarray for plotting.\n","training_array = np.asarray(training_metrics, dtype=np.float32)\n","test_array = np.asarray(test_metrics, dtype=np.float32)\n","\n","# Plotting error metric.\n","fig, ax = plt.subplots(1, 2, figsize = (16, 8), sharex=False, sharey=True)\n","\n","ax[0].plot(training_array)\n","ax[0].set_xlabel('Training Loss Progression')\n","\n","ax[1].plot(test_array)\n","ax[1].set_xlabel('Test Loss Progression')\n","\n","plt.show()\n","\n","for i in range(10):\n","    print('Actual: %.4f, Predicted: %.4f' % (label_array[i], output_array[i]))"],"execution_count":0,"outputs":[]}]}