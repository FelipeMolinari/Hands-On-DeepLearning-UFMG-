{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"MLP_Classification_Olivetti.ipynb","provenance":[{"file_id":"1iBi6UeyI2-l9lZBve2SQiv3EIL9Wt-Ai","timestamp":1581121682363},{"file_id":"1Y1skfCJXPaZD7urPYYGOrNMaFSGU6h7v","timestamp":1581113055073},{"file_id":"1xEP0AA_NpC_P-XpdnxL1O7Ny9sHc8uF-","timestamp":1581112306324},{"file_id":"1Ryrv4mhgBXqllQNu5mWHH8En5O-WjCf7","timestamp":1532878867492}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Il7H73VGJ2No"},"source":["# Training Procedure\n","\n","Imports básicos."]},{"cell_type":"code","metadata":{"id":"5LaoPWO9RhEq","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","import torch\n","\n","import PIL\n","\n","from sklearn import datasets\n","\n","from skimage import io"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5yNikfN0J2Np"},"source":["## Setting data loader\n","\n","Criando um dataloader customizado para o dataset Olivetti. Para mais informações sobre o dataset, acesse a página: <https://scikit-learn.org/0.19/modules/generated/sklearn.datasets.fetch_olivetti_faces.html#sklearn.datasets.fetch_olivetti_faces>."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YKPo231vJ2Nq","colab":{}},"source":["from torch.utils.data import DataLoader\n","from torch.utils import data\n","\n","from matplotlib import pyplot as plt\n","\n","%matplotlib inline\n","\n","# Creating custom dataloader.\n","class CustomDataset(data.Dataset):\n","\n","    def __init__(self, mode):\n","        \n","        super(CustomDataset, self).__init__()\n","        \n","        # Initializing variables.\n","        self.mode = mode\n","\n","        # Creating dataset from sklean.\n","        self.make_dataset()\n","\n","    def make_dataset(self):\n","\n","        # Downloading (if needed) dataset and getting features/labels.\n","        faces = datasets.fetch_olivetti_faces(data_home='./',\n","                                              download_if_missing=True,\n","                                              return_X_y=False)\n","\n","        # Dividing between training and testing sets.\n","        np.random.seed(1234) # Setting random seed for numpy.\n","        perm = np.random.permutation(faces.data.shape[0])\n","\n","        if self.mode == 'train':\n","            \n","            # Slicing training data/labels.\n","            self.X = faces.data[perm[:int(0.8 * perm.shape[0])]] # Perm.\n","            self.Y = faces.target[perm[:int(0.8 * perm.shape[0])]] # Perm.\n","            # self.X = faces.data[:int(0.8 * perm.shape[0])] # No perm.\n","            # self.Y = faces.target[:int(0.8 * perm.shape[0])] # No perm.\n","            \n","            # Computing average and standard deviation from training set.\n","            self.avg = self.X.mean()\n","            self.std = self.X.std()\n","            \n","            # Printing dataset size.\n","            print('Training features: ' + str(self.X.shape))\n","            print('Training labels: ' + str(self.Y.shape))\n","\n","        elif self.mode == 'test':\n","            \n","            # Slicing training data/labels (for computing avg and std).\n","            X_train = faces.data[perm[:int(0.8 * perm.shape[0])]] # Perm.\n","            Y_train = faces.target[perm[:int(0.8 * perm.shape[0])]] # Perm.\n","            # X_train = faces.data[:int(0.8 * perm.shape[0])] # No perm.\n","            # Y_train = faces.target[:int(0.8 * perm.shape[0])] # No perm.\n","            \n","            # Computing average and standard deviation from training set.\n","            self.avg = X_train.mean()\n","            self.std = X_train.std()\n","            \n","            # Slicing test data/labels.\n","            self.X = faces.data[perm[int(0.8 * perm.shape[0]):]] # Perm.\n","            self.Y = faces.target[perm[int(0.8 * perm.shape[0]):]] # Perm.\n","            # self.X = faces.data[int(0.8 * perm.shape[0]):] # No perm.\n","            # self.Y = faces.target[int(0.8 * perm.shape[0]):] # No perm.\n","            \n","            # Printing dataset size.\n","            print('Test features: ' + str(self.X.shape))\n","            print('Test labels: ' + str(self.Y.shape))\n","\n","    def __getitem__(self, index):\n","        \n","        # Recovering sample and label according to index.\n","        data = self.X[index]\n","        label = self.Y[index]\n","        \n","        # Normalizing data.\n","        data = (data - self.avg) / self.std\n","        \n","        # Turning data to Pytorch tensors.\n","        data = torch.from_numpy(data.astype(np.float32))\n","        label = torch.from_numpy(np.asarray(label, dtype=np.long))\n","        \n","        # Returning data and label to iterator.\n","        return data, label\n","\n","    def __len__(self):\n","\n","        return self.X.shape[0]\n","\n","# Instancing training and testing sets.\n","train_set = CustomDataset('train')\n","test_set = CustomDataset('test')\n","\n","# Printing/plotting samples.\n","print(train_set[0])\n","print(test_set[0])\n","\n","fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n","\n","ax[0].imshow(train_set[0][0].reshape(64, 64))\n","ax[0].set_yticks([])\n","ax[0].set_xticks([])\n","\n","ax[1].imshow(test_set[0][0].reshape(64, 64))\n","ax[1].set_yticks([])\n","ax[1].set_xticks([])\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrMULqqYShdC","colab_type":"code","colab":{}},"source":["# Creating data loaders.\n","batch_size = 1000\n","\n","train_loader = DataLoader(train_set, batch_size, shuffle=True)\n","test_loader = DataLoader(test_set, batch_size, shuffle=False)\n","\n","for i, data in enumerate(train_loader):\n","    \n","    inps, labs = data\n","    print(inps.size(), labs.size())\n","    print('')\n","\n","    if i > 5:\n","        break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EGtnadiqJ2Nu"},"source":["## Setting architecture\n","\n","Defina a arquitetura da sua Rede Neural. O pacote torch.nn que contém as implementações de todas as camadas que serão usadas nessa parte (nn.Linear): <https://pytorch.org/docs/stable/nn.html>."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P4oFGFAKJ2Nv","colab":{}},"source":["import torch.nn as nn\n","\n","# Random initialization for weights and biases.\n","def initialize_weights(*models):\n","    for model in models:\n","        for module in model.modules():\n","            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n","                nn.init.kaiming_normal_(module.weight)\n","                if module.bias is not None:\n","                    module.bias.data.zero_()\n","            elif isinstance(module, nn.BatchNorm2d):\n","                module.weight.data.fill_(1)\n","                module.bias.data.zero_()\n","\n","# Customized Network.\n","class CustomNetwork(nn.Module):\n","    \n","    def __init__(self, input_size, n_classes):\n","\n","        super(CustomNetwork, self).__init__()\n","        \n","        '''\n","        Exercício 1.1: crie uma Rede Neural totalmente conectada com 1 camada\n","        escondida que faça classificação das amostras do dataset Olivetti. \n","        Essa camada escondida deve receber o tamanho input_size (4096 para o\n","        Olivetti) e gerar n_classes de saída (40 para o Olivetti).\n","        '''\n","        ###################################################\n","        # Neural Network architecture. 1 hidden layer. ####\n","        ###################################################\n","        self.layer1 = # TO DO...\n","\n","        '''\n","        Exercício 5.1: expanda sua Rede Neural totalmente conectada para que ela\n","        tenha uma capacidade maior (mais parâmetros). Sua rede deve ter entre 2\n","        e 4 camadas escondidas e ir diminuindo o número de features\n","        progressivamente ao longo essas camadas. Cada camada intermediária deve\n","        receber o output da última camada. A primeira camada deve receber\n","        input_size features e a última camada deve gerar n_classes features que\n","        farão as predições entre as classes do Olivetti. Adicione ativações ReLU\n","        após todas as camadas nn.Linear, menos na última, que não deve ter\n","        nenhuma ativação.\n","        '''\n","        # ###################################################\n","        # # Neural Network architecture. 2~4 hidden layers. #\n","        # ###################################################\n","        # self.layer1 = # TO DO... Criar primeira camada linear.\n","        # self.ativ1 = # TO DO... Criar ativação da primeira camada.\n","        \n","        # self.layer2 = # TO DO... Criar segunda camada linear.\n","        # self.ativ2 = # TO DO... Criar ativação da segunda camada.\n","\n","        # # TO DO... Criar outras camadas/ativações, se achar necessário\n","\n","    # Forward function.\n","    def forward(self, x):\n","\n","        '''\n","        Exercício 1.2: Alimente os dados para a camada da sua rede. Para\n","        alimentar um dado x para uma certa camada self.camada_n:\n","        saida = self.camada_n(x).\n","        '''\n","        ###################################################\n","        # Forwarding through the single hidden layer. #####\n","        ###################################################\n","        out = # TO DO... Passar o input x pela camada self.layer1.\n","\n","        '''\n","        Exercício 5.2: Atualize a sua função forward para a nova arquitetura da\n","        sua rede com mais de uma camada.\n","        '''\n","        # ###################################################\n","        # # Forwarding through all layers. ##################\n","        # ###################################################\n","        # out = # TO DO... Passar o input x sequencialmente pelas camadas da rede.\n","        \n","        # Returning output.\n","        return # TO DO... Lembre-se de sempre retornar a saída da última camada.\n","        \n","# Instancing Network.\n","input_size = 4096 # Input size (number of features).\n","n_classes = 40 # Number of classes.\n","\n","# model = CustomNetwork(input_size) # CPU version.\n","model = CustomNetwork(input_size, n_classes).cuda() # GPU casting.\n","\n","initialize_weights(model)\n","\n","# Printing NN.\n","print(model)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VOVXXfCiJ2Ny"},"source":["## Setting optimizer\n","\n","O $Pytorch$ tem várias opções de otimizadores, desde os mais simples como o SGD até adaptadores mais modernos com velocidades de aprendizado adaptáveis para cada parâmetro da rede (i.e. Adam, Adagrad, RSMProp...). Todos os otimizadores estão localizados no pacote torch.optim. Para mais informnações sobre o pacote, visite: <https://pytorch.org/docs/stable/optim.html>."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fhyopppRJ2Nz","colab":{}},"source":["import torch.optim as optim\n","\n","lr = # TO DO...\n","l2_normalization = 0.00005 # L2 Normalization via weight decay.\n","\n","'''\n","Exercício 2: defina um otimizador. Comece pelo mais básico: o SGD. Experimente\n","diferentes learning rates para o otimizador e observe como isso afeta a\n","otimização da loss durante o treinamento/teste.\n","'''\n","optimizer = # TO DO...\n","\n","\n","'''\n","Exercício 6: utilize um otimizador mais poderoso como o Adam. Note que ele\n","possui parâmetros levemente diferentes do SGD.\n","'''\n","# optimizer = # TO DO..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MlBTGdzPJ2N1"},"source":["## Setting loss criterion\n","\n","Definindo um critério (loss) de classificação para calcular o erro do seu modelo a cada batch de amostras. A $CrossEntropyLoss$ ou a $NLLLoss$ são funções de perda indicadas para esse tipo de tarefa. Informações sobre essas losses podem ser encontradas em: <https://pytorch.org/docs/stable/nn.html#loss-functions>. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H1WirBm_J2N2","colab":{}},"source":["# Setting classification loss.\n","'''\n","Exercício 3: Defina uma loss function. Lembre-se de fazer o casting da loss para\n","a GPU assim como fizemos na rede.\n","'''\n","criterion = # TO DO..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"d9uC1yHfJ2N4"},"source":["## Training/Testing\n","\n","Iterando sobre batches de treino e teste ao longo de várias epochs."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"04-4qarbJ2N5","colab":{}},"source":["from matplotlib import pyplot as plt\n","from torch.autograd import Variable\n","\n","%matplotlib inline\n","\n","epochs = 20 # Number of training and testing epochs.\n","\n","training_metrics = list() # List for accuracies in training procedure.\n","test_metrics = list() # List for accuracies in test procedure.\n","\n","# Iterating over epochs.\n","for ep in range(epochs):\n","    \n","    print('##############################################')\n","    print('Starting epoch ' + str(ep + 1) + '/' + str(epochs) + '...')\n","    \n","    #####################################################################\n","    # Training Procedure. ###############################################\n","    #####################################################################\n","    \n","    print('    Training...')\n","    \n","    # Setting model to training mode.\n","    model.train()\n","    \n","    # Iterating over training batches.\n","    for it, data in enumerate(train_loader):\n","\n","        # Obtaining data and labels for batch.\n","        inps, labs = data\n","        \n","        # GPU casting. In CPU version comment the following two lines.\n","        inps = inps.cuda()\n","        labs = labs.cuda()\n","        \n","        # Zeroing optimizer.\n","        optimizer.zero_grad()\n","        \n","        '''\n","        Exercício 4: faça o forward do dado através da rede (de modo parecido\n","        com o que foi feito na função forward). Com os outputs gerados pela\n","        rede, calcule a loss para o mini-batch atual de acordo com o criterion\n","        previamente definido. Lembre-se de fazer a mesma\n","        coisa no procedimento de teste.\n","        '''\n","        # Forwarding inps through NN.\n","        output = # TO DO... Passar os inputs através da rede.\n","        \n","        # Computing loss according to network prediction for batch and targets.\n","        loss = # TO DO... Calcular a loss de acordo com o criterion previamente definido.\n","        \n","        # Backpropagating loss.\n","        loss.backward()\n","        \n","        # Taking optimization step (updating NN weights).\n","        optimizer.step()\n","        \n","        # Appending metric for batch.\n","        training_metrics.append(loss.mean())\n","\n","    #####################################################################\n","    # Testing Procedure.  ###############################################\n","    #####################################################################\n","    \n","    print('    Testing...')\n","    \n","    # Setting model to evaluation mode.\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        label_list = list()\n","        output_list = list()\n","\n","        # Iterating over test batches.\n","        for it, data in enumerate(test_loader):\n","            \n","            # Obtaining images and labels for batch.\n","            inps, labs = data\n","            \n","            # GPU casting. In CPU version comment the following line.\n","            inps = inps.cuda()\n","            labs = labs.cuda()\n","            \n","            # Forwarding through NN.\n","            output = # TO DO... Passar os inputs através da rede.\n","            \n","            # Computing loss according to network prediction for batch and targets.\n","            loss = # TO DO... Calcular a loss de acordo com o criterion previamente definido.\n","\n","            # Appending metric for batch.\n","            test_metrics.append(loss.mean())\n","\n","            # Getting labels and predictions from last epoch.\n","            label_list += labs.cpu().numpy().tolist()\n","            output_list += output.max(1)[1].cpu().numpy().tolist()\n","\n","        label_array = np.asarray(label_list, dtype=np.int).ravel()\n","        output_array = np.asarray(output_list, dtype=np.int).ravel()\n","\n","        print('Epoch: %d, Accuracy: %.2f%%' % (ep + 1, 100.0 * np.sum(label_array == output_array) / float(label_array.shape[0])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t8iWQH_grcP-","colab_type":"code","colab":{}},"source":["# Transforming list into ndarray for plotting.\n","training_array = np.asarray(training_metrics, dtype=np.float32)\n","test_array = np.asarray(test_metrics, dtype=np.float32)\n","\n","# Plotting error metric.\n","fig, ax = plt.subplots(1, 2, figsize = (16, 8), sharex=False, sharey=True)\n","\n","ax[0].plot(training_array)\n","ax[0].set_xlabel('Training Loss Progression')\n","\n","ax[1].plot(test_array)\n","ax[1].set_xlabel('Test Loss Progression')\n","\n","plt.show()\n","\n","for i in range(10):\n","    print('Actual: %.4f, Predicted: %.4f' % (label_array[i], output_array[i]))"],"execution_count":0,"outputs":[]}]}